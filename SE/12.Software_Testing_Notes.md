# Software Testing Notes

## Introduction to Software Testing

Software testing validates that a system meets requirements and is free of defects, ensuring quality, reliability, and user satisfaction. It integrates with SDLC phases to mitigate risks and optimize performance.

### What is Software Testing?

* **Definition**: Software testing is the process of validating that actual results match expected results, ensuring the system is bug-free.
* **Purpose**: Verifies functionality, performance, and compliance with requirements, reducing defects before release.
* **Example**: For an Online Fashion Store (OFS), testing ensures the checkout process correctly processes payments and updates inventory.
* **Role in SDLC**: Runs parallel to development, validating each phase (e.g., design, implementation) against SRS requirements.

### Importance of Software Testing

* **Risk Mitigation**: Identifies defects early, reducing costs and risks (e.g., catching OFS payment bugs during development).
* **Confidence**: Ensures software works as intended before release (e.g., OFS checkout reliability).
* **Compliance**: Verifies adherence to standards, critical for safety-critical systems.
* **User Satisfaction**: Validates usability and functionality, enhancing user experience (e.g., intuitive OFS interface).
* **Optimization**: Provides feedback for improving quality, security, and performance.
* **Cost Savings**: Reduces post-release defect costs by fixing issues early.
* **Example**: Testing OFS’s payment system prevents financial losses from transaction errors.

## Verification and Validation

Verification and validation ensure the software is built correctly and meets user needs, forming the foundation of effective testing.

### Software Verification

* **Definition**: Confirms the software meets design specifications and follows proper methodologies.
* **Purpose**: Ensures the product is developed according to business and technical requirements.
* **Focus**: Design and system specifications.
* **Example**: Verifying OFS’s Java code adheres to UML class diagrams for the `Order` class.
* **Key Concepts**:

  * **Errors**: Coding mistakes (e.g., incorrect OFS payment calculation logic).
  * **Faults (Bugs)**: Errors causing incorrect behavior (e.g., a bug in OFS order processing).
  * **Failures**: System inability to perform tasks due to faults (e.g., OFS checkout crashing).
* **Analogy**: A doctor diagnosing a patient’s illness (fault) from symptoms (failures) caused by abnormal conditions (errors).

### Software Validation

* **Definition**: Examines whether the software satisfies user requirements, conducted at the end of SDLC.
* **Purpose**: Ensures the product meets user needs and expectations.
* **Focus**: User requirements.
* **Example**: Validating OFS allows users to browse and purchase products as specified in the SRS.
* **Question Answered**: “Are we building the right product for the user?”

## Testing Approaches

Testing approaches include manual and automated methods, with black-box and white-box techniques addressing functionality and implementation, respectively.

### Manual vs. Automated Testing

* **Manual Testing**:

  * Performed without tools, using manually created test cases.
  * Time and resource-intensive but suitable for simple tests (e.g., checking OFS webpage rendering in a browser).
  * Example: Manually testing OFS login functionality.
* **Automated Testing**:

  * Uses tools to execute tests, overcoming manual limitations.
  * Ideal for complex tests like load testing (e.g., OFS handling 1 million users).
  * Example: Using Selenium to automate OFS checkout tests.
* **Tools**: Support load, stress, and regression testing (e.g., JMeter for OFS performance tests).

### Black-Box Testing

* **Definition**: Tests functionality without knowledge of code structure, also called behavioral testing.
* **Process**: Tester provides inputs and checks outputs against expected results.
* **Techniques**:

  * **Equivalence Class**: Groups similar inputs, assuming one test represents the class (e.g., testing OFS prices in a range).
  * **Boundary Values**: Tests edge cases (e.g., OFS cart with 0 or maximum items).
  * **Cause-Effect Graphing**: Tests input combinations systematically.
  * **Pairwise Testing**: Tests parameter pairs for interactions.
  * **State-Based Testing**: Tests system states (e.g., OFS order states: pending, shipped).

### White-Box Testing

* **Definition**: Tests code structure and implementation to improve efficiency, also called structural testing.
* **Process**: Tester knows the code, testing all statements and variables.
* **Techniques**:

  * **Control-Flow Testing**: Covers all code paths (e.g., testing OFS payment logic branches).
  * **Data-Flow Testing**: Tracks variable usage (e.g., OFS price variable initialization and updates).

### Comparison

* **Black-Box**:

  * Focus: Functionality.
  * Knowledge: None of code structure.
* **White-Box**:

  * Focus: Code structure and efficiency.
  * Knowledge: Full code access.

## Testing Levels

Testing occurs at multiple SDLC levels, from unit testing to acceptance testing, ensuring each phase meets quality standards.

### Unit Testing

* **Definition**: Tests individual code units (e.g., functions, methods) for errors using white-box techniques.

### Integration Testing

* **Definition**: Tests interactions between units to ensure they work together.

### System Testing

* **Definition**: Tests the compiled software as a whole against requirements.
* **Types**:

  * **Functionality Testing**
  * **Performance Testing**
  * **Security and Portability**

### Acceptance Testing

* **Definition**: Tests user interaction and response before release.
* **Types**:

  * **Alpha Testing**
  * **Beta Testing**

### Regression Testing

* **Definition**: Tests updated software to ensure new code doesn’t introduce defects.

## Testing Documentation

Testing documentation tracks requirements, test cases, and results, ensuring traceability and project transparency.

### Before Testing

* **SRS Document**
* **Test Policy Document**
* **Test Strategy Document**
* **Traceability Matrix**

### During Testing

* **Test Case Document**
* **Test Description**
* **Test Case Report**
* **Test Logs**

### After Testing

* **Test Summary**
* **Version Control**

## Testing vs. Quality Assurance, Control, and Audit

Testing is distinct from quality assurance, control, and audit, each contributing to software quality in unique ways.

### Software Quality Assurance (SQA)

* **Definition**: Monitors development processes to ensure adherence to standards.

### Software Quality Control

* **Definition**: Maintains product quality, including functional and non-functional aspects.

### Software Audit

* **Definition**: Reviews development procedures by an independent team.

## Software Quality Metrics

Software quality metrics quantify product and process attributes, guiding improvements and management decisions.

### Measurement Concepts

* **Measurement**
* **Measure**
* **Metric**

### What to Measure

* **Process**
* **Project**
* **Product**

### Types of Metrics

* **Process Metrics**
* **Project Metrics**
* **Product Metrics**
* **Software Quality Metrics**:

  * **Defect Density**
  * **Code Coverage**
  * **Cyclomatic Complexity**
  * **Fault Tolerance**
  * **Performance Testing**

### Test Metrics Life Cycle

* **Analysis**
* **Communicate**
* **Evaluation**
* **Report**

### Test Metrics Formulas

* Percentage Test Cases Executed
* Test Case Effectiveness
* Passed/Failed/Blocked Test Cases Percentages
* Fixed/Accepted/Deferred Defects Percentages
* Rework Effort Ratio

### Software Size Metrics

* **KLOC**
* **Number of Function Points (NFP)**

## Practical Notes for Software Testing

Software testing ensures quality by validating and verifying systems across SDLC phases, using metrics to measure effectiveness and guide improvements.

### Best Practices

* Align with Requirements
* Use UML Diagrams
* Select Testing Approach
* Automate Where Possible
* Document Thoroughly
* Measure Quality
* Version Control
* Secure Testing

### Example Application

For an Online Fashion Store:

* Combine black-box and white-box testing.
* Apply testing levels from unit to acceptance.
* Measure execution, defect detection, and fix rates.
* Document all tests for traceability.
* Ensure readiness for release through summarized metrics.
